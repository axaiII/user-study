# user-study
强化学习是一种从试错过程中发现最优行为策略的技术，已经成为解决环境交互问题的通用方法。然而，作为一类机器学习算法，强化学习也面临着机器学习领域的公共难题，即难以被人理解。缺乏可解释性限制了强化学习在安全敏感领域中的应用，如医疗、驾驶等。为了克服强化学习的这一弱点，我们对强化学习的可解释性进行了探索。拟采用策略图对智能体的行为进行解释，其中策略图的节点代表智能体的状态，边代表智能体的动作。通过查看策略图，用户可以了解在给定的状态下智能体的决策过程。为了验证策略图的有效性，我们计划在Mountain Car和CartPole这两个任务上进行用户研究。Mountain Car和Cartpole是Gym上的两个经典控制任务。Mountain Car和Cartpole是Gym上的两个经典控制任务。前者旨在使小车到达右侧山顶的预定位置，后者则要求小车保持滑道中央且杆子直立。在每个任务上，我们使用了三种不同的算法来训练智能体，并为每种算法训练的智能体生成了对应的策略图。我们计划通过问卷调查来测试这些策略图是否有效。针对不同任务，我们还编写了相应的用户手册（包含问卷链接，题目类型）。填写问卷前请仔细阅读用户手册，以下是用户手册链接：
- [mountain car用户手册](https://github.com/axaiII/user-study/blob/main/mountain%20car%E7%94%A8%E6%88%B7%E6%89%8B%E5%86%8C.pdf)
- [cartpole用户手册](https://github.com/axaiII/user-study/blob/main/cartpole%E7%94%A8%E6%88%B7%E6%89%8B%E5%86%8C.pdf)<br>

对于完成全部6份问卷的同学，我们将提供相应的奖励。为了便于后续发放奖励，请在每份问卷的最后一页填写姓名和学号。具体奖励措施如下：
- 若每份问卷的答题时间都超过8分钟，将会获得50元的基础奖励；
- 若每份问卷的答题时间都超过8分钟，当总体准确率(6份问卷)高于50%时，每提高10%，将获得10元的额外奖励；
- 此外，针对无效试卷，我们将酌情给予奖励。

完成所有问卷的同学请加入下群，核实问卷情况后，将会发放奖励。
<img src=''>
